#import required library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from xgboost import XGBRegressor

# Load training data from CSV
train_df = pd.read_csv('/content/drive/MyDrive/FBI - Time series Project/Test (2).csv')

# Load test data from Excel
test_df = pd.read_excel('/content/drive/MyDrive/FBI - Time series Project/Train.xlsx')

print("Train Shape:", train_df.shape)
print("Test Shape:", test_df.shape)

# check column
print("Train DataFrame Columns:", train_df.columns)
print("Test DataFrame Columns:", test_df.columns)

# check if data is balanced/imbalanced
print(train_df['TYPE'].value_counts())

# check missing values
print(train_df.isnull().sum())

test_df.isnull().sum()

#check duplicate value
train_df.duplicated().sum()

test_df.duplicated().sum()
test_df.drop_duplicates()

#column and datatype info
test_df.info()

#descriptive statistic
test_df.describe()

test_df.nunique()

#To see which columns have missing values.
#Missing data can affect analysis and model performance
missing = test_df.isnull().mean().sort_values(ascending=False) * 100
missing = missing[missing > 0]

plt.figure(figsize=(10, 4))
sns.barplot(x=missing.index, y=missing.values)
plt.ylabel("Missing Percentage")
plt.title("Missing Data Overview")
plt.xticks(rotation=45)
plt.show()

#types of crimes happen most frequently
top_types = test_df['TYPE'].value_counts().head(10)

plt.figure(figsize=(10, 5))
sns.barplot(y=top_types.index, x=top_types.values, palette='Reds_r')
plt.xlabel("Number of Incidents")
plt.title("Top 10 Crime Types")
plt.show()

#how crime changes throughout the year.
monthly_trend = test_df.groupby('MONTH').size()

plt.figure(figsize=(10, 4))
sns.lineplot(x=monthly_trend.index, y=monthly_trend.values, marker='o')
plt.title("Incidents by Month")
plt.xticks(range(1, 13))
plt.ylabel("Count")
plt.grid()
plt.show()

#long-term trends, like rising or falling crime
daily_trend = test_df.groupby('Date').size()

plt.figure(figsize=(14, 4))
daily_trend.plot()
plt.title("Daily Crime Trend")
plt.ylabel("Incidents per Day")
plt.grid()
plt.tight_layout()
plt.show()

# what time crimes mostly occur
plt.figure(figsize=(10, 4))
sns.countplot(data=test_df.dropna(subset=['HOUR']), x='HOUR', palette='coolwarm')
plt.title("Crimes by Hour of the Day")
plt.show()

#where crimes are happening most
top_neighbourhoods = test_df['NEIGHBOURHOOD'].value_counts().head(10)

plt.figure(figsize=(10, 5))
sns.barplot(y=top_neighbourhoods.index, x=top_neighbourhoods.values, palette='viridis')
plt.xlabel("Number of Incidents")
plt.title("Top 10 Neighbourhoods with Most Crimes")
plt.show()

# 1. Group by YEAR, MONTH, TYPE to count incidents
train_df = test_df.groupby(['YEAR', 'MONTH', 'TYPE']).size().reset_index(name='Incident_Counts')

# 2. Encode 'TYPE' for modeling
le = LabelEncoder()
train_df['TYPE_ENCODED'] = le.fit_transform(train_df['TYPE'])

# 3. Define features (X) and label (y)
X_train = train_df[['YEAR', 'MONTH', 'TYPE_ENCODED']]
y_train = train_df['Incident_Counts']

# 4. Scale features
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)

# 5. Train model
model = XGBRegressor(objective='reg:squarederror', random_state=42)
model.fit(X_train_scaled, y_train)

print("✅ Model trained successfully!")

features = ['YEAR', 'MONTH', 'TYPE_ENCODED']
target = 'Incident_Counts'

X = train_df[features]
y = train_df[target]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
model.fit(X_train_scaled, y_train)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

y_pred = model.predict(X_test_scaled)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.2f}")
print(f"MSE: {mse:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

plt.scatter(y_test, y_pred, alpha=0.4, color='teal')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red')
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Incident Counts")
plt.grid(True)
plt.show()

print(train_df['TYPE'].unique())

# Prepare prediction data
future_data = pd.DataFrame({
    'YEAR': [2026],
    'MONTH': [6],
    'TYPE': ['Offence Against a Person']  # Example
})

# Encode and scale
future_data['TYPE_ENCODED'] = le.transform(future_data['TYPE'])
X_future = future_data[['YEAR', 'MONTH', 'TYPE_ENCODED']]
X_future_scaled = scaler.transform(X_future)

# Predict
y_pred = model.predict(X_future_scaled)
print(f"Predicted Incident Count: {y_pred[0]:.2f}")
